# Kaggle Datasets - Commodity Price Data

A comprehensive Python project for downloading, processing, and exporting commodity price data from FRED (Federal Reserve Economic Data) in multiple formats (CSV, JSON, Parquet).

## üìä Datasets

### Crude Oil Brent Prices

**Description**: Daily crude oil Brent prices in USD per barrel from the Federal Reserve Economic Data (FRED) API.

**Data Source**: [FRED Series DCOILBRENTEU](https://fred.stlouisfed.org/series/DCOILBRENTEU)

**Time Range**: 2020-11-17 to Present (continuously updated)

**Total Records**: 1,265+ price observations

**Price Range**: $42.54 - $133.18 per barrel

**Update Frequency**: Weekly (automated via cron job)

**Columns**:
- `Date` (date): Trading date
- `Price` (float): Daily closing price in USD/barrel
- `Year` (int): Year extracted from date
- `Month` (int): Month extracted from date (1-12)
- `Day` (int): Day extracted from date (1-31)

### Henry Hub Natural Gas Spot Prices

**Description**: Daily Henry Hub natural gas spot prices in USD per million BTU from the U.S. Energy Information Administration (EIA).

**Data Source**: [EIA Henry Hub Natural Gas Spot Price - Daily](https://www.eia.gov/dnav/ng/hist_xls/RNGWHHDd.xls)

**Time Range**: 1997-01-07 to Present (continuously updated)

**Total Records**: 7,252+ price observations

**Price Range**: $1.05 - $23.86 per Million BTU

**Update Frequency**: Daily (automated via cron job)

**Columns**:
- `Date` (date): Trading date
- `Price` (float): Daily spot price in USD/Million BTU
- `Year` (int): Year extracted from date
- `Month` (int): Month extracted from date (1-12)
- `Day` (int): Day extracted from date (1-31)

## üöÄ Quick Start

### Prerequisites

- **Python 3.13+** (required)
- **[uv](https://docs.astral.sh/uv/)** - Fast Python package installer and resolver (recommended)
  - Install: `curl -LsSf https://astral.sh/uv/install.sh | sh` (macOS/Linux)
  - Or: `powershell -Command "irm https://astral.sh/uv/install.ps1 | iex"` (Windows)

### Installation with uv (Recommended)

```bash
# Clone repository and navigate to directory
git clone https://github.com/deepu-peddineni/KaggleDataset.git
cd KaggleDataset

# Create and activate virtual environment with uv
uv venv

# Activate the environment
source .venv/bin/activate  # macOS/Linux
# or
.venv\Scripts\activate  # Windows

# Install dependencies using uv (fast, deterministic)
uv sync
```

### Installation with pip (Alternative)

```bash
# Clone repository and navigate to directory
git clone https://github.com/deepu-peddineni/KaggleDataset.git
cd KaggleDataset

# Create and activate virtual environment
python3.13 -m venv .venv
source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -e .
```

### Package Management with uv

#### Add Dependencies
```bash
# Add a new production dependency
uv add polars>=1.35.0

# Add a development-only dependency
uv add --dev pytest

# Add to specific group
uv add --group dev pytest-cov
```

#### Update Dependencies
```bash
# Update all dependencies to latest compatible versions
uv sync --upgrade

# Update a specific package
uv pip install --upgrade polars
```

#### View Dependency Tree
```bash
# Show all installed packages and their versions
uv pip list

# Show dependency details
uv pip show polars
```

#### Lock File Management
```bash
# Generate/update uv.lock (committed to git)
uv lock

# Install from lock file (deterministic, reproducible builds)
uv sync --frozen  # Error if lock file needs update
```

### Running the Data Pipeline

```bash
# Download latest Crude Oil data and export to all formats
python CrudeOil/crude_oil_brent.py

# Download latest Henry Hub Natural Gas data and export to all formats
python HenryHub/henry_hub_downloader.py
```

**Crude Oil Output**:
```
================================================================================
Crude Oil Brent Data Downloader & Processor
================================================================================
Timestamp: 2025-11-24 20:50:49

Downloading Crude Oil Brent data from FRED...
‚úì Data downloaded successfully (Status: 200)
‚úì CSV parsed successfully - 1265 rows

Sample Data (First 10 rows)
[Data table showing oldest prices]

‚úì Existing file loaded - 1265 rows
‚úì No new records to add - data is up to date
‚úì Combined data - 1265 total rows
‚úì Data tracker saved to ./CrudeOil/crude_oil_brent.csv

Exporting Data
‚úì CSV exported to ./CrudeOil/csv/crude_oil_brent.csv
‚úì JSON exported to ./CrudeOil/json/crude_oil_brent.json
‚úì Parquet exported to ./CrudeOil/parquet/crude_oil_brent.parquet

Process completed successfully!
```

**Henry Hub Output**:
```
================================================================================
Henry Hub Natural Gas Spot Price Downloader & Processor
================================================================================
Timestamp: 2025-11-24 21:03:02

Downloading Henry Hub Natural Gas data from EIA...
‚úì Data downloaded successfully (Status: 200)
‚úì Excel parsed successfully - 7252 rows

Sample Data (First 10 rows)
[Data table showing prices from 1997]

‚úì Creating new dataset
‚úì Data tracker saved to ./HenryHub/henry_hub_natural_gas.csv

Exporting Data
‚úì CSV exported to ./HenryHub/csv/henry_hub_natural_gas.csv
‚úì JSON exported to ./HenryHub/json/henry_hub_natural_gas.json
‚úì Parquet exported to ./HenryHub/parquet/henry_hub_natural_gas.parquet

Process completed successfully!
```

## üìÅ Project Structure

```
KaggleDataset/
‚îú‚îÄ‚îÄ pyproject.toml                  # Project metadata & uv config
‚îú‚îÄ‚îÄ uv.lock                         # Lock file (deterministic dependencies)
‚îú‚îÄ‚îÄ .pre-commit-config.yaml         # Git hooks for code quality
‚îú‚îÄ‚îÄ setup.cfg                       # Additional tool configuration
‚îú‚îÄ‚îÄ .gitignore                      # Git exclusion patterns
‚îú‚îÄ‚îÄ README.md                       # This file
‚îÇ
‚îú‚îÄ‚îÄ CrudeOil/
‚îÇ   ‚îú‚îÄ‚îÄ crude_oil_brent.py          # Main data downloader & processor script
‚îÇ   ‚îú‚îÄ‚îÄ crude_oil_brent.csv         # Data tracker (for duplicate detection)
‚îÇ   ‚îú‚îÄ‚îÄ csv/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crude_oil_brent.csv     # CSV export (1,265 rows, 34 KB)
‚îÇ   ‚îú‚îÄ‚îÄ json/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crude_oil_brent.json    # JSON export (1,265 rows, 85 KB)
‚îÇ   ‚îî‚îÄ‚îÄ parquet/
‚îÇ       ‚îî‚îÄ‚îÄ crude_oil_brent.parquet # Parquet export (1,265 rows, 9.1 KB)
‚îÇ
‚îú‚îÄ‚îÄ HenryHub/
‚îÇ   ‚îú‚îÄ‚îÄ henry_hub_downloader.py     # Natural Gas data downloader & processor
‚îÇ   ‚îú‚îÄ‚îÄ henry_hub_natural_gas.csv   # Data tracker (for duplicate detection)
‚îÇ   ‚îú‚îÄ‚îÄ csv/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ henry_hub_natural_gas.csv     # CSV export (7,252 rows, 95 KB)
‚îÇ   ‚îú‚îÄ‚îÄ json/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ henry_hub_natural_gas.json    # JSON export (7,252 rows, 285 KB)
‚îÇ   ‚îî‚îÄ‚îÄ parquet/
‚îÇ       ‚îî‚îÄ‚îÄ henry_hub_natural_gas.parquet # Parquet export (7,252 rows, 28 KB)
‚îÇ
‚îî‚îÄ‚îÄ .venv/                          # Virtual environment (uv venv)
```

## üîß Project Configuration with uv

### pyproject.toml Overview

```toml
[project]
name = "kaggledataset"
version = "0.1.0"
requires-python = ">=3.13"
dependencies = [
    "polars>=1.35.2",      # DataFrame library
    "pandas>=2.3.3",       # Data manipulation
    "requests>=2.32.5",    # HTTP requests
    "duckdb>=1.4.2",       # SQL queries on data
    "pyarrow>=22.0.0",     # Parquet support
    "xlrd>=2.0.2",         # XLS file reading
    "openpyxl>=3.1.5",     # XLSX support
    "fastexcel>=0.18.0",   # Fast Excel parsing
    "ruff>=0.14.6",        # Formatter & linter
    "mypy>=1.18.2",        # Type checker
]

[project.optional-dependencies]
dev = [
    "pre-commit>=3.5.0",   # Git hooks
    "pytest>=7.4.3",       # Testing framework
    "pytest-cov>=4.1.0",   # Coverage reports
    "bandit>=1.7.5",       # Security analyzer
]
```

### uv.lock - Dependency Lock File

The `uv.lock` file ensures reproducible builds:

```bash
# Generated automatically by uv
# Pinned versions prevent surprises in CI/CD and production
uv sync --frozen  # Uses locked versions, fails if out of sync
```

Benefits:
- ‚úì Deterministic builds across machines
- ‚úì Exact version reproduction
- ‚úì Faster dependency resolution
- ‚úì Security: no version surprises

## üõ†Ô∏è Common uv Workflows

### Development Workflow

```bash
# Clone and setup with uv
git clone https://github.com/deepu-peddineni/KaggleDataset.git
cd KaggleDataset

# Create virtual environment and install all dependencies
uv venv
source .venv/bin/activate
uv sync

# Install development dependencies too
uv sync --all-groups
```

### Add New Dependency

```bash
# Add production dependency
uv add requests-retry

# Add development dependency
uv add --group dev pytest-xdist

# Add optional dependency group
uv add --optional test pytest

# Update lock file (done automatically)
git add uv.lock pyproject.toml
git commit -m "chore: add new dependencies"
```

### Upgrade Dependencies

```bash
# Upgrade all to latest compatible versions
uv lock --upgrade

# Upgrade specific package to latest
uv lock --upgrade-package polars

# Check for outdated packages
uv pip list --outdated
```

### Run Scripts with uv

```bash
# Run Python script in project environment
uv run python CrudeOil/crude_oil_brent.py

# Run with specific Python version
uv run --python 3.13 HenryHub/henry_hub_downloader.py

# Run tests
uv run pytest tests/

# Run formatter
uv run ruff format .

# Run linter
uv run ruff check . --fix
```

### Docker with uv

```dockerfile
FROM python:3.13-slim
WORKDIR /app

# Install uv
RUN pip install uv

# Copy project
COPY pyproject.toml uv.lock ./

# Install dependencies
RUN uv sync --frozen --no-dev

# Run application
CMD ["uv", "run", "python", "CrudeOil/crude_oil_brent.py"]
```

### CI/CD with uv

```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v3
      - uses: actions/setup-python@v5
        with:
          python-version: "3.13"
      - run: uv sync --all-groups
      - run: uv run pytest
      - run: uv run ruff format --check .
      - run: uv run ruff check .
```

## üìä uv vs pip - Comparison

| Feature | pip | uv |
|---------|-----|-----|
| **Speed** | Slow (serial resolution) | üöÄ **10-100x faster** |
| **Lock File** | ‚ùå No native support | ‚úì `uv.lock` built-in |
| **Deterministic Builds** | ‚ùå Requires pip-tools | ‚úì Native |
| **Dependency Resolution** | ‚ùå Backtracking only | ‚úì Full SAT solver |
| **Installation** | `pip install` | `uv add` |
| **Update All** | Manual process | `uv lock --upgrade` |
| **Memory Usage** | High | **Low** |
| **Virtual Environments** | `venv` module | `uv venv` (integrated) |
| **Reproducibility** | Difficult | **Easy with uv.lock** |
| **Developer Experience** | Basic | **Rich output, progress bars** |

### Quick Command Comparison

```bash
# Creating environment
pip: python -m venv .venv
uv:  uv venv

# Installing dependencies
pip: pip install -r requirements.txt
uv:  uv sync

# Adding package
pip: pip install package && pip freeze > requirements.txt
uv:  uv add package  # Auto-updates uv.lock

# Upgrading all
pip: pip install --upgrade pip && pip install -r requirements.txt --upgrade
uv:  uv lock --upgrade

# Running scripts
pip: python script.py
uv:  uv run python script.py
```

## üìñ Usage Examples

### Python - Reading Data with Polars

```python
import polars as pl

# Read CSV
df_csv = pl.read_csv("CrudeOil/csv/crude_oil_brent.csv")
print(df_csv.head())
print(f"Total records: {len(df_csv)}")

# Read Parquet (fastest, compressed)
df_parquet = pl.read_parquet("CrudeOil/parquet/crude_oil_brent.parquet")

# Read JSON
df_json = pl.read_json("CrudeOil/json/crude_oil_brent.json")

# Filter and analyze
recent = df_csv.filter(pl.col("Year") == 2025)
avg_price = recent.select(pl.col("Price").mean()).item()
print(f"Average 2025 price: ${avg_price:.2f}")

# Group by month and calculate statistics
monthly_stats = df_csv.group_by("Month").agg(
    pl.col("Price").mean().alias("avg_price"),
    pl.col("Price").min().alias("min_price"),
    pl.col("Price").max().alias("max_price"),
    pl.col("Price").count().alias("observations")
)
print(monthly_stats)
```

### Python - Pandas Alternative

```python
import pandas as pd

# Read CSV
df = pd.read_csv("CrudeOil/csv/crude_oil_brent.csv")

# Convert Date column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Filter 2024 data
df_2024 = df[df['Year'] == 2024]
print(f"2024 average price: ${df_2024['Price'].mean():.2f}")

# Time series plot
df.set_index('Date')['Price'].plot(figsize=(12, 6))
plt.title('Brent Crude Oil Prices')
plt.ylabel('Price (USD/barrel)')
plt.show()
```

### SQL Query - DuckDB

```python
import duckdb

# Query Parquet file directly
result = duckdb.query("""
    SELECT
        Year,
        Month,
        COUNT(*) as trading_days,
        AVG(Price) as avg_price,
        MIN(Price) as min_price,
        MAX(Price) as max_price
    FROM 'CrudeOil/parquet/crude_oil_brent.parquet'
    WHERE Year >= 2024
    GROUP BY Year, Month
    ORDER BY Year, Month
""").to_df()

print(result)
```

### Command Line - DuckDB

```bash
# Query directly from command line
duckdb << EOF
SELECT Date, Price, Year, Month
FROM 'CrudeOil/parquet/crude_oil_brent.parquet'
WHERE Price > 100
ORDER BY Price DESC
LIMIT 10;
EOF
```

## üîÑ Data Pipeline Features

### Intelligent Duplicate Detection
- Maintains tracker file (`crude_oil_brent.csv` in root)
- Only adds new records on subsequent runs
- Compares dates to avoid duplicates
- Efficient incremental updates

### Multi-Format Export
- **CSV**: Universal format, human-readable, easy to share
- **JSON**: Preserves date types, API-friendly
- **Parquet**: Compressed columnar format, optimal for analytics

### Type Preservation
```
CSV:     Date as ISO string (YYYY-MM-DD), Price/Year/Month/Day as text
JSON:    Date as ISO string, numeric fields preserve types
Parquet: Full type preservation (Date type, Float64, Int32, Int8)
```

### Data Quality
- ‚úì No duplicate records
- ‚úì Proper type casting (dates, integers, floats)
- ‚úì Complete year/month/day extraction
- ‚úì Chronologically sorted (newest first)

## üõ†Ô∏è Code Quality & Security

### Pre-commit Hooks
Automated checks on every git commit:

```bash
# Manual pre-commit run
pre-commit run --all-files
```

**Checks performed**:
- ‚úì File size limits (max 1000 KB)
- ‚úì YAML/JSON/TOML syntax validation
- ‚úì Python syntax checking
- ‚úì Secret detection (credentials, API keys)
- ‚úì Code security analysis (bandit)
- ‚úì Python formatting (ruff format)
- ‚úì Code linting (ruff check)
- ‚úì Trailing whitespace removal
- ‚úì Line ending normalization

### Python Tools Configuration

**Ruff** (Formatter & Linter):
```toml
# pyproject.toml
line-length = 100
target-version = "py312"
```

**MyPy** (Type Checker):
```bash
mypy CrudeOil/crude_oil_brent.py
```

## üìÖ Automation

### Weekly Cron Job Setup

```bash
# Edit crontab
crontab -e

# Add weekly update (Sundays at 2 AM)
0 2 * * 0 cd /path/to/KaggleDataset && source .venv/bin/activate && python CrudeOil/crude_oil_brent.py >> cron.log 2>&1
```

### Manual Update

```bash
source .venv/bin/activate
python CrudeOil/crude_oil_brent.py
```

## üìä Data Statistics

**Crude Oil Dataset** (as of 2025-11-24):
- Total records: 1,265
- Date range: 2020-11-17 to 2025-11-17
- Price range: $42.54 - $133.18/barrel
- Average price: $76.42/barrel
- Highest price: $133.18 (2022-03-08)
- Lowest price: $42.54 (2020-11-17)

**Henry Hub Natural Gas Dataset** (as of 2025-11-24):
- Total records: 7,252
- Date range: 1997-01-07 to 2025-11-17
- Price range: $1.05 - $23.86/Million BTU
- Average price: $5.42/Million BTU
- Highest price: $23.86 (2022-03-07)
- Lowest price: $1.05 (2020-04-20)

**File Sizes**:
- Crude Oil CSV: 34 KB | JSON: 85 KB | Parquet: 9.1 KB
- Henry Hub CSV: 95 KB | JSON: 285 KB | Parquet: 28 KB

## üîê Environment Variables

No API key required for FRED public data. All requests are unauthenticated GET requests.

## ‚ö° uv Best Practices

### Project Setup Checklist

```bash
# ‚úì Initialize with pyproject.toml
uv venv
source .venv/bin/activate
uv sync

# ‚úì Commit lock file to git
git add uv.lock
git commit -m "chore: add uv.lock for reproducible builds"

# ‚úì Use specific version constraints
uv add "polars>=1.35,<2.0"  # More specific than >=1.35

# ‚úì Separate dev dependencies
uv add --group dev pytest

# ‚úì Pin Python version in pyproject.toml
# requires-python = ">=3.13"
```

### Dependency Management Tips

```bash
# Check for security vulnerabilities
uv pip audit

# See dependency tree
uv tree

# Verify reproducibility
uv sync --frozen --all-groups

# Keep lock file up-to-date
git diff uv.lock  # Review changes before committing
```

### Team Collaboration

```bash
# When pulling changes with new dependencies
uv sync

# When adding dependencies
uv add package-name
git add uv.lock pyproject.toml
git push

# CI should use --frozen for reproducibility
uv sync --frozen --all-groups
```

### Performance Tips

```bash
# Use uv.lock for production deployments
# Skip development dependencies
uv sync --frozen

# Cache dependencies in Docker
# Place COPY pyproject.toml uv.lock before COPY .
RUN uv sync --frozen

# Use --no-binary for specific packages if needed
uv add --no-binary package-name
```

## üêõ Troubleshooting

### Date Type Mismatch Error
```
Error: type Date is incompatible with expected type String
```
**Solution**: The script automatically handles this by casting loaded CSV dates to Date type for comparison.

### Missing Newline Error
```
Failed: end-of-file-fixer
Fixing CrudeOil/json/crude_oil_brent.json
```
**Solution**: The script automatically appends newlines to JSON files after export.

### Pre-commit Hook Failures
```bash
# Fix all auto-fixable issues
pre-commit run --all-files --fix

# Run specific hook
pre-commit run ruff --all-files
```

### uv Installation Issues

```bash
# If uv command not found, reinstall
curl -LsSf https://astral.sh/uv/install.sh | sh

# Update uv to latest version
uv self update

# Clear uv cache if corrupted
uv cache clean
```

## üìù Script Internals

### Download Process
1. GET request to FRED API with 35+ query parameters
2. Parse CSV response with Polars
3. Rename columns and extract date components
4. Return DataFrame with 1,265 records

### Deduplication Process
1. Load existing tracker file
2. Compare dates between existing and new data
3. Filter only missing dates
4. Merge and sort chronologically

### Export Process
1. Convert Date column to string for CSV
2. Write CSV (34 KB)
3. Write JSON with newline (85 KB)
4. Write Parquet with compression (9.1 KB)

## ü§ù Contributing

When adding new datasets:

1. Create new directory under project root
2. Implement processor script following existing pattern
3. Update `.pre-commit-config.yaml` if needed
4. Add documentation to README.md
5. Test with `pre-commit run --all-files`

## üìÑ License

This project uses public data from FRED (Federal Reserve Economic Data).

## üîó Resources

- [FRED API Documentation](https://fred.stlouisfed.org/docs/api/)
- [DCOILBRENTEU Series](https://fred.stlouisfed.org/series/DCOILBRENTEU)
- [Polars Documentation](https://docs.pola-rs.com/)
- [Parquet Format](https://parquet.apache.org/)
- [Pre-commit Framework](https://pre-commit.com/)

## üìû Support

For issues or questions:
1. Check the Troubleshooting section above
2. Review script output carefully
3. Verify FRED API is accessible
4. Check git status and pre-commit logs
